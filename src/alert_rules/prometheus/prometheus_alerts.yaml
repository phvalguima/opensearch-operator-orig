"groups":
- "name": "opensearch.alerts"
  "rules":

  # Write requests rates
  # =====================
  - record: write:rejected_requests:rate2m
    expr: sum by (cluster, instance, node) (rate(opensearch_threadpool_threads_count{name="write", type="rejected"}[2m]))

  - record: write:total_requests:rate2m
    expr: sum by (cluster, instance, node) (rate(opensearch_threadpool_threads_count{name="write"}[2m]))

  # If there are no write rejections then we get can 0/0 which is NaN. This does not affect the
  # OpenSearchWriteRequestsRejectionJumps alert
  - record: write:reject_ratio:rate2m
    expr: write:rejected_requests:rate2m / write:total_requests:rate2m

  - "alert": "OpenSearchScrapeFailed"
    "annotations":
      "message": "Scrape on {{ $labels.juju_unit }} failed. Ensure that the OpenSearch systemd service is healthy and that the unit is part of the cluster."
      "summary": "OpenSearch exporter scrape failed"
    "expr": |
      up < 1
    "for": "5m"
    "labels":
      "severity": "critical"

  - "alert": "OpenSearchClusterRed"
    "annotations":
      "message": "Cluster {{ $labels.cluster }} health status has been RED for at least 2m. Cluster does not accept writes, shards may be missing or master node hasn't been elected yet."
      "summary": "Cluster health status is RED"
    "expr": |
      sum by (cluster) (opensearch_cluster_status == 2)
    "for": "2m"
    "labels":
      "severity": "critical"

  - "alert": "OpenSearchClusterYellowTemp"
    "annotations":
      "message": "Cluster {{ $labels.cluster }} health status has been YELLOW for at least 20m. Shards are still relocating or initializing. The cluster might be under heavy load."
      "summary": "Cluster health status is temporarily YELLOW"
    "expr": |
      sum by (cluster) (opensearch_cluster_shards_number{type=~"relocating|initializing"}) > 0 and on(cluster) opensearch_cluster_status == 1
    "for": "20m"
    "labels":
      "severity": "warning"

  - "alert": "OpenSearchClusterYellow"
    "annotations":
      "message": "Cluster {{ $labels.cluster }} health status has been YELLOW. Some replica shards are unassigned."
      "summary": "Number of nodes in the cluster might be too low. Consider scaling the application to ensure that it has enough nodes to host all shards."
    "expr": |
      sum by (cluster) (opensearch_cluster_shards_number{type="unassigned"}) > 0 and on(cluster) opensearch_cluster_status == 1
    "for": "10m"
    "labels":
      "severity": "warning"

  - "alert": "OpenSearchWriteRequestsRejectionJumps"
    "annotations":
      "message": "High Write Rejection Ratio at {{ $labels.node }} node in {{ $labels.cluster }} cluster. This node may not be keeping up with the indexing speed."
      "summary": "High Write Rejection Ratio - {{ $value }}%"
    "expr": |
      round( write:reject_ratio:rate2m * 100, 0.001 ) > 5
    "for": "10m"
    "labels":
      "severity": "warning"

  - "alert": "OpenSearchNodeDiskLowWatermarkReached"
    "annotations":
      "message": "Disk Low Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Shards can not be allocated to this node anymore. You should consider adding more disk to the node."
      "summary": "Disk Low Watermark Reached - disk saturation is {{ $value }}%"
    "expr": |
      sum by (cluster, instance, node) (
        round(
          (1 - (
            opensearch_fs_path_available_bytes /
            opensearch_fs_path_total_bytes
          )
        ) * 100, 0.001)
      ) > 85
    "for": "5m"
    "labels":
      "severity": "alert"

  - "alert": "OpenSearchNodeDiskHighWatermarkReached"
    "annotations":
      "message": "Disk High Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Some shards will be re-allocated to different nodes if possible. Make sure more disk space is added to the node or drop old indices allocated to this node."
      "summary": "Disk High Watermark Reached - disk saturation is {{ $value }}%"
    "expr": |
      sum by (cluster, instance, node) (
        round(
          (1 - (
            opensearch_fs_path_available_bytes /
            opensearch_fs_path_total_bytes
          )
        ) * 100, 0.001)
      ) > 90
    "for": "5m"
    "labels":
      "severity": "high"

  - "alert": "OpenSearchJVMHeapUseHigh"
    "annotations":
      "message": "JVM Heap usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%."
      "summary": "JVM Heap usage on the node is high"
    "expr": |
      sum by (cluster, instance, node) (opensearch_jvm_mem_heap_used_percent) > 75
    "for": "10m"
    "labels":
      "severity": "alert"

  - "alert": "OpenSearchHostSystemCPUHigh"
    "annotations":
      "message": "System CPU usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%"
      "summary": "System CPU usage is high"
    "expr": |
      sum by (cluster, instance, node) (opensearch_os_cpu_percent) > 90
    "for": "1m"
    "labels":
      "severity": "alert"

  - "alert": "OpenSearchProcessCPUHigh"
    "annotations":
      "message": "OSE process CPU usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%"
      "summary": "OSE process CPU usage is high"
    "expr": |
      sum by (cluster, instance, node) (opensearch_process_cpu_percent) > 90
    "for": "1m"
    "labels":
      "severity": "alert"
